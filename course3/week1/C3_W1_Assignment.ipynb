{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimize models using Automatic Model Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "When training ML models, hyperparameter tuning is a step taken to find the best performing training model. In this lab you will apply a random algorithm of Automated Hyperparameter Tuning to train a BERT-based natural language processing (NLP) classifier. The model analyzes customer feedback and classifies the messages into positive (1), neutral (0), and negative (-1) sentiments.\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "- [1. Configure dataset and Hyperparameter Tuning Job (HTP)](#c3w1-1.)\n",
    "  - [1.1. Configure dataset](#c3w1-1.1.)\n",
    "    - [Exercise 1](#c3w1-ex-1)\n",
    "  - [1.2. Configure Hyperparameter Tuning Job](#c3w1-1.2.)\n",
    "  - [1.3. Set up evaluation metrics](#c3w1-1.3.)\n",
    "- [2. Run tuning job](#c3w1-2.)\n",
    "  - [2.1. Set up the RoBERTa and PyTorch script to run on SageMaker](#c3w1-2.1.)\n",
    "  - [2.2. Launch the Hyperparameter Tuning Job](#c3w1-2.2.)\n",
    "    - [Exercise 2](#c3w1-ex-2)\n",
    "    - [Exercise 3](#c3w1-ex-3)\n",
    "  - [2.3. Check Tuning Job status](#c3w1-2.3.)\n",
    "- [3. Evaluate the results](#c3w1-3.)\n",
    "  - [3.1. Show the best candidate](#c3w1-3.1.)\n",
    "    - [Exercise 4](#c3w1-ex-4)\n",
    "  - [3.2. Evaluate the best candidate](#c3w1-3.2.)\n",
    "    - [Exercise 5](#c3w1-ex-5)\n",
    "    - [Exercise 6](#c3w1-ex-6)\n",
    "    - [Exercise 7](#c3w1-ex-7)\n",
    "  - [3.3. Inspect the processed output data](#c3w1-3.3.)\n",
    "\n",
    "Amazon SageMaker supports Automated Hyperparameter Tuning. It runs multiple training jobs on the training dataset using the hyperparameter ranges specified by the user. Then it chooses the combination of hyperparameters that leads to the best model candidate. The choice is made based on the objective metrics, e.g. maximization of the validation accuracy. \n",
    "\n",
    "For the choice of hyperparameters combinations, SageMaker supports two different types of tuning strategies: random and Bayesian. This capability can be further extended by providing an implementation of a custom tuning strategy as a Docker container."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/hpt.png\" width=\"70%\" align=\"center\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab you will perform the following three steps:\n",
    "\n",
    "<img src=\"images/sagemaker_hpt.png\" width=\"50%\" align=\"center\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's install and import the required modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/secretstorage/dhcrypto.py:16: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "/opt/conda/lib/python3.7/site-packages/secretstorage/util.py:25: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "/opt/conda/lib/python3.7/site-packages/secretstorage/dhcrypto.py:16: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "/opt/conda/lib/python3.7/site-packages/secretstorage/util.py:25: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# please ignore warning messages during the installation\n",
    "!pip install --disable-pip-version-check -q sagemaker==2.35.0\n",
    "!conda install -q -y pytorch==1.6.0 -c pytorch\n",
    "!pip install --disable-pip-version-check -q transformers==3.5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "import botocore\n",
    "\n",
    "config = botocore.config.Config(user_agent_extra='dlai-pds/c3/w1')\n",
    "\n",
    "# low-level service client of the boto3 session\n",
    "sm = boto3.client(service_name='sagemaker', \n",
    "                  config=config)\n",
    "\n",
    "sess = sagemaker.Session(sagemaker_client=sm)\n",
    "\n",
    "bucket = sess.default_bucket()\n",
    "role = sagemaker.get_execution_role()\n",
    "region = sess.boto_region_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='c3w1-1.'></a>\n",
    "# 1. Configure dataset and Hyperparameter Tuning Job (HTP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='c3w1-1.1.'></a>\n",
    "### 1.1. Configure dataset\n",
    "\n",
    "Let's set up the paths and copy the data to the S3 bucket:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_train_data_s3_uri = 's3://{}/transformed/data/sentiment-train/'.format(bucket)\n",
    "processed_validation_data_s3_uri = 's3://{}/transformed/data/sentiment-validation/'.format(bucket)\n",
    "processed_test_data_s3_uri = 's3://{}/transformed/data/sentiment-test/'.format(bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload the data to the S3 bucket:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: data/sentiment-train/part-algo-1-womens_clothing_ecommerce_reviews.tsv to s3://sagemaker-us-east-1-593402094095/transformed/data/sentiment-train/part-algo-1-womens_clothing_ecommerce_reviews.tsv\n",
      "upload: data/sentiment-validation/part-algo-1-womens_clothing_ecommerce_reviews.tsv to s3://sagemaker-us-east-1-593402094095/transformed/data/sentiment-validation/part-algo-1-womens_clothing_ecommerce_reviews.tsv\n",
      "upload: data/sentiment-test/part-algo-1-womens_clothing_ecommerce_reviews.tsv to s3://sagemaker-us-east-1-593402094095/transformed/data/sentiment-test/part-algo-1-womens_clothing_ecommerce_reviews.tsv\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp --recursive ./data/sentiment-train $processed_train_data_s3_uri\n",
    "!aws s3 cp --recursive ./data/sentiment-validation $processed_validation_data_s3_uri\n",
    "!aws s3 cp --recursive ./data/sentiment-test $processed_test_data_s3_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the existence of those files in the S3 bucket:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-16 08:57:37    4894416 transformed/data/sentiment-train/part-algo-1-womens_clothing_ecommerce_reviews.tsv\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls --recursive $processed_train_data_s3_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-16 08:57:37     276522 transformed/data/sentiment-validation/part-algo-1-womens_clothing_ecommerce_reviews.tsv\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls --recursive $processed_validation_data_s3_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-16 08:57:38     273414 transformed/data/sentiment-test/part-algo-1-womens_clothing_ecommerce_reviews.tsv\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls --recursive $processed_test_data_s3_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='c3w1-ex-1'></a>\n",
    "### Exercise 1\n",
    "\n",
    "Set up a dictionary of the input training and validation data channels, wrapping the corresponding S3 locations in a `TrainingInput` object.\n",
    "\n",
    "**Instructions**: Pass the S3 input paths for training and validation data into the `TrainingInput` function\n",
    "\n",
    "```python\n",
    "TrainingInput(s3_data=...)\n",
    "```\n",
    "\n",
    "to construct the Amazon SageMaker channels for S3 input data sources. Then put the corresponding channels into the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.inputs import TrainingInput\n",
    "\n",
    "data_channels = {\n",
    "    ### BEGIN SOLUTION - DO NOT delete this comment for grading purposes\n",
    "    'train': processed_train_data_s3_uri, # Replace None\n",
    "    'validation': processed_validation_data_s3_uri # Replace None\n",
    "    ### END SOLUTION - DO NOT delete this comment for grading purposes\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no need to create a test data channel, as the test data is used later at the evaluation stage and does not need to be wrapped into the `sagemaker.inputs.TrainingInput` function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='c3w1-1.2.'></a>\n",
    "### 1.2. Configure Hyperparameter Tuning Job\n",
    "\n",
    "Model hyperparameters need to be set prior to starting the model training as they control the process of learning. Some of the hyperparameters you will set up as static - they will not be explored during the tuning job. For the non-static hyperparameters you will set the range of possible values to be explored.\n",
    "\n",
    "First, configure static hyperparameters including the instance type, instance count, maximum sequence length, etc. For the purposes of this lab, you will use a relatively small instance type. Please refer to [this link](https://aws.amazon.com/sagemaker/pricing/) for additional instance types that may work for your use cases outside of this lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "max_seq_length=128 # maximum number of input tokens passed to BERT model\n",
    "freeze_bert_layer=False # specifies the depth of training within the network\n",
    "epochs=3\n",
    "train_steps_per_epoch=50\n",
    "validation_batch_size=64\n",
    "validation_steps_per_epoch=50\n",
    "seed=42\n",
    "\n",
    "train_instance_count=1\n",
    "train_instance_type='ml.c5.9xlarge'\n",
    "train_volume_size=256\n",
    "input_mode='File'\n",
    "run_validation=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of these will be passed into the PyTorch estimator and tuner in the hyperparameters argument. Let's set up the dictionary for that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters_static={\n",
    "    'freeze_bert_layer': freeze_bert_layer,\n",
    "    'max_seq_length': max_seq_length,\n",
    "    'epochs': epochs,\n",
    "    'train_steps_per_epoch': train_steps_per_epoch,\n",
    "    'validation_batch_size': validation_batch_size,\n",
    "    'validation_steps_per_epoch': validation_steps_per_epoch,\n",
    "    'seed': seed,\n",
    "    'run_validation': run_validation\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure hyperparameter ranges to explore in the Tuning Job. The values of the ranges typically come from prior experience, research papers, or other models similar to the task you are trying to do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tuner import IntegerParameter\n",
    "from sagemaker.tuner import ContinuousParameter\n",
    "from sagemaker.tuner import CategoricalParameter\n",
    "                                                \n",
    "hyperparameter_ranges = {\n",
    "    'learning_rate': ContinuousParameter(0.00001, 0.00005, scaling_type='Linear'), # specifying continuous variable type, the tuning job will explore the range of values\n",
    "    'train_batch_size': CategoricalParameter([128, 256]), # specifying categorical variable type, the tuning job will explore only listed values\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='c3w1-1.3.'></a>\n",
    "### 1.3. Set up evaluation metrics\n",
    "\n",
    "Choose loss and accuracy as the evaluation metrics. The regular expressions `Regex` will capture the values of metrics that the algorithm will emit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_definitions = [\n",
    "     {'Name': 'validation:loss', 'Regex': 'val_loss: ([0-9.]+)'},\n",
    "     {'Name': 'validation:accuracy', 'Regex': 'val_acc: ([0-9.]+)'},\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, these sample log lines...\n",
    "```\n",
    "[step: 100] val_loss: 0.76 - val_acc: 70.92%\n",
    "```\n",
    "\n",
    "...will produce the following metrics in CloudWatch:\n",
    "\n",
    "`validation:loss` =  0.76\n",
    "\n",
    "`validation:accuracy` = 70.92"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Tuning Job, you will be maximizing validation accuracy as the objective metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='c3w1-2.'></a>\n",
    "# 2. Run Tuning Job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='c3w1-2.1.'></a>\n",
    "### 2.1. Set up the RoBERTa and PyTorch script to run on SageMaker\n",
    "\n",
    "Prepare the PyTorch model to run as a SageMaker Training Job. The estimator takes into the entry point a separate Python file, which will be called during the training. You can open and review this file [src/train.py](src/train.py).\n",
    "\n",
    "For more information on the `PyTorchEstimator`, see the documentation here: https://sagemaker.readthedocs.io/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorch as PyTorchEstimator\n",
    "# Note: indeed, it is not compulsory to rename the PyTorch estimator,\n",
    "# but this is useful for code clarity, especially when a few modules of 'sagemaker.pytorch' are used\n",
    "\n",
    "estimator = PyTorchEstimator(\n",
    "    entry_point='train.py',\n",
    "    source_dir='src',\n",
    "    role=role,\n",
    "    instance_count=train_instance_count,\n",
    "    instance_type=train_instance_type,\n",
    "    volume_size=train_volume_size,\n",
    "    py_version='py3',\n",
    "    framework_version='1.6.0',\n",
    "    hyperparameters=hyperparameters_static,\n",
    "    metric_definitions=metric_definitions,\n",
    "    input_mode=input_mode,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='c3w1-2.2.'></a>\n",
    "### 2.2. Launch the Hyperparameter Tuning Job\n",
    "\n",
    "A hyperparameter tuning job runs a series of training jobs that each test a combination of hyperparameters for a given objective metric (i.e. `validation:accuracy`). In this lab, you will use a `Random` search strategy to determine the combinations of hyperparameters - within the specific ranges - to use for each training job within the tuning job.  For more information on hyperparameter tuning search strategies, please see the following documentation:  https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-how-it-works.html\n",
    "\n",
    "When the tuning job completes, you can select the hyperparameters used by the best-performing training job relative to the objective metric. \n",
    "\n",
    "The `max_jobs` parameter is a stop criteria that limits the number of overall training jobs (and therefore hyperparameter combinations) to run within the tuning job.\n",
    "\n",
    "The `max_parallel_jobs` parameter limits the number of training jobs (and therefore hyperparameter combinations) to run in parallel within the tuning job.  This parameter is often used in combination with the `Bayesian` search strategy when you want to test a smaller set of training jobs (less than the `max_jobs`), learn from the smaller set of training jobs, then apply Bayesian methods to determine the next set of hyperparameters used by the next set of training jobs. Bayesian methods can improve hyperparameter-tuning performance in some cases.\n",
    "\n",
    "\n",
    "The `early_stopping_type` parameter is used by SageMaker hyper-parameter tuning jobs to automatically stop a training job if the job is not improving the objective metrics (i.e. `validation:accuracy`) relative to previous training jobs within the tuning job.  For more information on early stopping, please see the following documentation:  https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-early-stopping.html."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='c3w1-ex-2'></a>\n",
    "### Exercise 2\n",
    "\n",
    "Set up the Hyperparameter Tuner.\n",
    "\n",
    "**Instructions**: Use the function `HyperparameterTuner`, passing the variables defined above. Please use tuning strategy `'Random'`.\n",
    "\n",
    "```python\n",
    "tuner = HyperparameterTuner(\n",
    "    estimator=..., # estimator\n",
    "    hyperparameter_ranges=..., # hyperparameter ranges\n",
    "    metric_definitions=..., # definition metric\n",
    "    strategy='...', # tuning strategy\n",
    "    objective_type='Maximize',\n",
    "    objective_metric_name='validation:accuracy',\n",
    "    max_jobs=2, # maximum number of jobs to run\n",
    "    max_parallel_jobs=2, # maximum number of jobs to run in parallel\n",
    "    early_stopping_type='Auto' # early stopping criteria\n",
    ")\n",
    "``` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tuner import HyperparameterTuner\n",
    "\n",
    "tuner = HyperparameterTuner(\n",
    "    ### BEGIN SOLUTION - DO NOT delete this comment for grading purposes\n",
    "    estimator=estimator, # Replace None\n",
    "    hyperparameter_ranges=hyperparameter_ranges, # Replace None\n",
    "    metric_definitions=metric_definitions, # Replace None\n",
    "    strategy='Random', # Replace None\n",
    "    ### END SOLUTION - DO NOT delete this comment for grading purposes\n",
    "    objective_type='Maximize',\n",
    "    objective_metric_name='validation:accuracy',\n",
    "    max_jobs=2, # maximum number of jobs to run\n",
    "    max_parallel_jobs=2, # maximum number of jobs to run in parallel\n",
    "    early_stopping_type='Auto' # early stopping criteria\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='c3w1-ex-3'></a>\n",
    "### Exercise 3\n",
    "\n",
    "Launch the SageMaker Hyper-Parameter Tuning (HPT) Job.\n",
    "\n",
    "**Instructions**: Use the `tuner.fit` function, passing the configured train and validation inputs (data channels).\n",
    "\n",
    "```python\n",
    "tuner.fit(\n",
    "    inputs=..., # train and validation input\n",
    "    include_cls_metadata=False, # to be set as false if the algorithm cannot handle unknown hyperparameters\n",
    "    wait=False # do not wait for the job to complete before continuing\n",
    ")\n",
    "``` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.fit(\n",
    "    ### BEGIN SOLUTION - DO NOT delete this comment for grading purposes\n",
    "    inputs=data_channels, # Replace None\n",
    "    ### END SOLUTION - DO NOT delete this comment for grading purposes\n",
    "    include_cls_metadata=False,\n",
    "    wait=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='c3w1-2.3.'></a>\n",
    "### 2.3. Check Tuning Job status\n",
    "You can see the Tuning Job status in the console. Let's get the Tuning Job name to construct the link."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytorch-training-210916-0857\n"
     ]
    }
   ],
   "source": [
    "tuning_job_name = tuner.latest_tuning_job.job_name\n",
    "print(tuning_job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the status of the Tuning Job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>Review <a target=\"blank\" href=\"https://console.aws.amazon.com/sagemaker/home?region=us-east-1#/hyper-tuning-jobs/pytorch-training-210916-0857\">Hyper-Parameter Tuning Job</a></b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "    \n",
    "display(HTML('<b>Review <a target=\"blank\" href=\"https://console.aws.amazon.com/sagemaker/home?region={}#/hyper-tuning-jobs/{}\">Hyper-Parameter Tuning Job</a></b>'.format(region, tuning_job_name)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wait for the Tuning Job to complete.\n",
    "\n",
    "### _This cell will take approximately 20-30 minutes to run._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..................................................................................................................................................................................................................................................................................................................................................................!\n",
      "CPU times: user 1.38 s, sys: 226 ms, total: 1.6 s\n",
      "Wall time: 29min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tuner.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Wait until the ^^ Tuning Job ^^ completes above_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results of the SageMaker Hyperparameter Tuning Job are available on the `analytics` of the `tuner object`. The `dataframe` function converts the result directly into the dataframe. You can explore the results with the following lines of the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 8)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "time.sleep(10) # slight delay to allow the analytics to be calculated\n",
    "\n",
    "df_results = tuner.analytics().dataframe()\n",
    "df_results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>train_batch_size</th>\n",
       "      <th>TrainingJobName</th>\n",
       "      <th>TrainingJobStatus</th>\n",
       "      <th>FinalObjectiveValue</th>\n",
       "      <th>TrainingStartTime</th>\n",
       "      <th>TrainingEndTime</th>\n",
       "      <th>TrainingElapsedTimeSeconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000020</td>\n",
       "      <td>\"128\"</td>\n",
       "      <td>pytorch-training-210916-0857-002-fd13714c</td>\n",
       "      <td>Completed</td>\n",
       "      <td>70.699997</td>\n",
       "      <td>2021-09-16 09:00:24+00:00</td>\n",
       "      <td>2021-09-16 09:25:10+00:00</td>\n",
       "      <td>1486.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000015</td>\n",
       "      <td>\"128\"</td>\n",
       "      <td>pytorch-training-210916-0857-001-fa4b6e1a</td>\n",
       "      <td>Stopped</td>\n",
       "      <td>37.110001</td>\n",
       "      <td>2021-09-16 09:01:06+00:00</td>\n",
       "      <td>2021-09-16 09:10:10+00:00</td>\n",
       "      <td>544.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   learning_rate train_batch_size                            TrainingJobName  \\\n",
       "0       0.000020            \"128\"  pytorch-training-210916-0857-002-fd13714c   \n",
       "1       0.000015            \"128\"  pytorch-training-210916-0857-001-fa4b6e1a   \n",
       "\n",
       "  TrainingJobStatus  FinalObjectiveValue         TrainingStartTime  \\\n",
       "0         Completed            70.699997 2021-09-16 09:00:24+00:00   \n",
       "1           Stopped            37.110001 2021-09-16 09:01:06+00:00   \n",
       "\n",
       "            TrainingEndTime  TrainingElapsedTimeSeconds  \n",
       "0 2021-09-16 09:25:10+00:00                      1486.0  \n",
       "1 2021-09-16 09:10:10+00:00                       544.0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results.sort_values('FinalObjectiveValue', ascending=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When training and tuning at scale, it is important to continuously monitor and use the right compute resources. While you have the flexibility of choosing different compute options how do you choose the specific instance types and sizes to use? There is no standard answer for this. It comes down to understanding the workload and running empirical testing to determine the best compute resources to use for the training. \n",
    "\n",
    "SageMaker Training Jobs emit CloudWatch metrics for resource utilization. You can review them in the AWS console:\n",
    "\n",
    "- open the link\n",
    "- notice that you are in the section Amazon SageMaker -> Hyperparameter tuning jobs\n",
    "- have a look at the list of the Training jobs below and click on one of them\n",
    "- scroll down to the Monitor section and review the available metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>Review Training Jobs of the <a target=\"blank\" href=\"https://console.aws.amazon.com/sagemaker/home?region=us-east-1#/hyper-tuning-jobs/pytorch-training-210916-0857\">Hyper-Parameter Tuning Job</a></b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "    \n",
    "display(HTML('<b>Review Training Jobs of the <a target=\"blank\" href=\"https://console.aws.amazon.com/sagemaker/home?region={}#/hyper-tuning-jobs/{}\">Hyper-Parameter Tuning Job</a></b>'.format(region, tuning_job_name)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='c3w1-3.'></a>\n",
    "# 3. Evaluate the results\n",
    "\n",
    "An important part of developing a model is evaluating the model with a test data set - one that the model has never seen during its training process. The final metrics resulting from this evaluation can be used to compare competing machine learning models. The higher the value of these metrics, the better the model is able to generalize."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='c3w1-3.1.'></a>\n",
    "### 3.1. Show the best candidate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='c3w1-ex-4'></a>\n",
    "### Exercise 4\n",
    "\n",
    "Show the best candidate - the one with the highest accuracy result.\n",
    "\n",
    "**Instructions**: Use the `sort_values` function to sort the results by accuracy, which is stored in the column `FinalObjectiveValue`. Put `ascending=0` and `head(1)` for the selection.\n",
    "\n",
    "```python\n",
    "df_results.sort_values(\n",
    "    '...', # column name for sorting\n",
    "    ascending=0).head(1)\n",
    "``` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>train_batch_size</th>\n",
       "      <th>TrainingJobName</th>\n",
       "      <th>TrainingJobStatus</th>\n",
       "      <th>FinalObjectiveValue</th>\n",
       "      <th>TrainingStartTime</th>\n",
       "      <th>TrainingEndTime</th>\n",
       "      <th>TrainingElapsedTimeSeconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00002</td>\n",
       "      <td>\"128\"</td>\n",
       "      <td>pytorch-training-210916-0857-002-fd13714c</td>\n",
       "      <td>Completed</td>\n",
       "      <td>70.699997</td>\n",
       "      <td>2021-09-16 09:00:24+00:00</td>\n",
       "      <td>2021-09-16 09:25:10+00:00</td>\n",
       "      <td>1486.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   learning_rate train_batch_size                            TrainingJobName  \\\n",
       "0        0.00002            \"128\"  pytorch-training-210916-0857-002-fd13714c   \n",
       "\n",
       "  TrainingJobStatus  FinalObjectiveValue         TrainingStartTime  \\\n",
       "0         Completed            70.699997 2021-09-16 09:00:24+00:00   \n",
       "\n",
       "            TrainingEndTime  TrainingElapsedTimeSeconds  \n",
       "0 2021-09-16 09:25:10+00:00                      1486.0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results.sort_values(\n",
    "    ### BEGIN SOLUTION - DO NOT delete this comment for grading purposes\n",
    "    'FinalObjectiveValue', # Replace None\n",
    "    ### END SOLUTION - DO NOT delete this comment for grading purposes\n",
    "    ascending=0).head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='c3w1-3.2.'></a>\n",
    "### 3.2. Evaluate the best candidate\n",
    "\n",
    "Let's pull the information about the best candidate from the dataframe and then take the Training Job name from the column `TrainingJobName`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best candidate Training Job name: pytorch-training-210916-0857-002-fd13714c\n"
     ]
    }
   ],
   "source": [
    "best_candidate = df_results.sort_values('FinalObjectiveValue', ascending=0).iloc[0]\n",
    "\n",
    "best_candidate_training_job_name = best_candidate['TrainingJobName']\n",
    "print('Best candidate Training Job name: {}'.format(best_candidate_training_job_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='c3w1-ex-5'></a>\n",
    "### Exercise 5\n",
    "\n",
    "Show accuracy result for the best candidate.\n",
    "\n",
    "**Instructions**: Use the example in the cell above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best candidate accuracy result: 70.69999694824219\n"
     ]
    }
   ],
   "source": [
    "### BEGIN SOLUTION - DO NOT delete this comment for grading purposes\n",
    "best_candidate_accuracy = best_candidate['FinalObjectiveValue'] # Replace all None\n",
    "### END SOLUTION - DO NOT delete this comment for grading purposes\n",
    "\n",
    "print('Best candidate accuracy result: {}'.format(best_candidate_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the function `describe_training_job` of the service client to get some more information about the best candidate. The result is in dictionary format. Let's check that it has the same Training Job name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Job name: pytorch-training-210916-0857-002-fd13714c\n"
     ]
    }
   ],
   "source": [
    "best_candidate_description = sm.describe_training_job(TrainingJobName=best_candidate_training_job_name)\n",
    "\n",
    "best_candidate_training_job_name2 = best_candidate_description['TrainingJobName']\n",
    "\n",
    "print('Training Job name: {}'.format(best_candidate_training_job_name2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='c3w1-ex-6'></a>\n",
    "### Exercise 6\n",
    "\n",
    "Pull the Tuning Job and Training Job Amazon Resource Name (ARN) from the best candidate training job description.\n",
    "\n",
    "**Instructions**: Print the keys of the best candidate Training Job description dictionary, choose the ones related to the Tuning Job and Training Job ARN and print their values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['TrainingJobName', 'TrainingJobArn', 'TuningJobArn', 'ModelArtifacts', 'TrainingJobStatus', 'SecondaryStatus', 'HyperParameters', 'AlgorithmSpecification', 'RoleArn', 'InputDataConfig', 'OutputDataConfig', 'ResourceConfig', 'StoppingCondition', 'CreationTime', 'TrainingStartTime', 'TrainingEndTime', 'LastModifiedTime', 'SecondaryStatusTransitions', 'FinalMetricDataList', 'EnableNetworkIsolation', 'EnableInterContainerTrafficEncryption', 'EnableManagedSpotTraining', 'TrainingTimeInSeconds', 'BillableTimeInSeconds', 'ProfilingStatus', 'ResponseMetadata'])\n"
     ]
    }
   ],
   "source": [
    "print(best_candidate_description.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best candidate Tuning Job ARN: arn:aws:sagemaker:us-east-1:593402094095:hyper-parameter-tuning-job/pytorch-training-210916-0857\n",
      "Best candidate Training Job ARN: arn:aws:sagemaker:us-east-1:593402094095:training-job/pytorch-training-210916-0857-002-fd13714c\n"
     ]
    }
   ],
   "source": [
    "### BEGIN SOLUTION - DO NOT delete this comment for grading purposes\n",
    "best_candidate_tuning_job_arn = best_candidate_description['TuningJobArn'] # Replace None\n",
    "best_candidate_training_job_arn = best_candidate_description['TrainingJobArn'] # Replace None\n",
    "### END SOLUTION - DO NOT delete this comment for grading purposes\n",
    "print('Best candidate Tuning Job ARN: {}'.format(best_candidate_tuning_job_arn))\n",
    "print('Best candidate Training Job ARN: {}'.format(best_candidate_training_job_arn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pull the path of the best candidate model in the S3 bucket. You will need it later to set up the Processing Job for the evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-593402094095/pytorch-training-210916-0857-002-fd13714c/output/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "model_tar_s3_uri = sm.describe_training_job(TrainingJobName=best_candidate_training_job_name)['ModelArtifacts']['S3ModelArtifacts']\n",
    "print(model_tar_s3_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform model evaluation you will use a scikit-learn-based Processing Job. This is essentially a generic Python Processing Job with scikit-learn pre-installed. You can specify the version of scikit-learn you wish to use. Also pass the SageMaker execution role, processing instance type and instance count. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "\n",
    "processing_instance_type = \"ml.c5.2xlarge\"\n",
    "processing_instance_count = 1\n",
    "\n",
    "processor = SKLearnProcessor(\n",
    "    framework_version=\"0.23-1\",\n",
    "    role=role,\n",
    "    instance_type=processing_instance_type,\n",
    "    instance_count=processing_instance_count,\n",
    "    max_runtime_in_seconds=7200,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model evaluation Processing Job will be running the Python code from the file [src/evaluate_model_metrics.py](src/evaluate_model_metrics.py). You can open and review the file.\n",
    "\n",
    "Launch the Processing Job, passing the defined above parameters, custom script, path and the S3 bucket location of the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Name:  sagemaker-scikit-learn-2021-09-16-09-27-40-683\n",
      "Inputs:  [{'InputName': 'model-tar-s3-uri', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-593402094095/pytorch-training-210916-0857-002-fd13714c/output/model.tar.gz', 'LocalPath': '/opt/ml/processing/input/model/', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'evaluation-data-s3-uri', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-593402094095/transformed/data/sentiment-test/', 'LocalPath': '/opt/ml/processing/input/data/', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'code', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-593402094095/sagemaker-scikit-learn-2021-09-16-09-27-40-683/input/code/evaluate_model_metrics.py', 'LocalPath': '/opt/ml/processing/input/code', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}]\n",
      "Outputs:  [{'OutputName': 'metrics', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-593402094095/sagemaker-scikit-learn-2021-09-16-09-27-40-683/output/metrics', 'LocalPath': '/opt/ml/processing/output/metrics', 'S3UploadMode': 'EndOfJob'}}]\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "\n",
    "processor.run(\n",
    "    code=\"src/evaluate_model_metrics.py\",\n",
    "    inputs=[\n",
    "        ProcessingInput(  \n",
    "            input_name=\"model-tar-s3-uri\",                        \n",
    "            source=model_tar_s3_uri,                               \n",
    "            destination=\"/opt/ml/processing/input/model/\"\n",
    "        ),\n",
    "        ProcessingInput(\n",
    "            input_name=\"evaluation-data-s3-uri\",\n",
    "            source=processed_test_data_s3_uri,                                    \n",
    "            destination=\"/opt/ml/processing/input/data/\",\n",
    "        ),\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(s3_upload_mode=\"EndOfJob\", output_name=\"metrics\", source=\"/opt/ml/processing/output/metrics\"),\n",
    "    ],\n",
    "    arguments=[\"--max-seq-length\", str(max_seq_length)],\n",
    "    logs=True,\n",
    "    wait=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see the information about the Processing Jobs using the `describe` function. The result is in dictionary format. Let's pull the Processing Job name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Job name: sagemaker-scikit-learn-2021-09-16-09-27-40-683\n"
     ]
    }
   ],
   "source": [
    "scikit_processing_job_name = processor.jobs[-1].describe()[\"ProcessingJobName\"]\n",
    "\n",
    "print('Processing Job name: {}'.format(scikit_processing_job_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='c3w1-ex-7'></a>\n",
    "### Exercise 7\n",
    "\n",
    "Pull the Processing Job status from the Processing Job description.\n",
    "\n",
    "**Instructions**: Print the keys of the Processing Job description dictionary, choose the one related to the status of the Processing Job and print the value of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['ProcessingInputs', 'ProcessingOutputConfig', 'ProcessingJobName', 'ProcessingResources', 'StoppingCondition', 'AppSpecification', 'RoleArn', 'ProcessingJobArn', 'ProcessingJobStatus', 'LastModifiedTime', 'CreationTime', 'ResponseMetadata'])\n"
     ]
    }
   ],
   "source": [
    "print(processor.jobs[-1].describe().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing job status: InProgress\n"
     ]
    }
   ],
   "source": [
    "### BEGIN SOLUTION - DO NOT delete this comment for grading purposes\n",
    "scikit_processing_job_status = processor.jobs[-1].describe()['ProcessingJobStatus'] # Replace None\n",
    "### END SOLUTION - DO NOT delete this comment for grading purposes\n",
    "print('Processing job status: {}'.format(scikit_processing_job_status))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review the created Processing Job in the AWS console.\n",
    "\n",
    "**Instructions**: \n",
    "- open the link\n",
    "- notice that you are in the section `Amazon SageMaker` -> `Processing Jobs`\n",
    "- check the name of the Processing Job, its status and other available information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>Review <a target=\"blank\" href=\"https://console.aws.amazon.com/sagemaker/home?region=us-east-1#/processing-jobs/sagemaker-scikit-learn-2021-09-16-09-27-40-683\">Processing Job</a></b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "display(\n",
    "    HTML(\n",
    "        '<b>Review <a target=\"blank\" href=\"https://console.aws.amazon.com/sagemaker/home?region={}#/processing-jobs/{}\">Processing Job</a></b>'.format(\n",
    "            region, scikit_processing_job_name\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wait for about 5 minutes to review the CloudWatch Logs. You may open the file [src/evaluate_model_metrics.py](src/evaluate_model_metrics.py) again and examine the outputs of the code in the CloudWatch Logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>Review <a target=\"blank\" href=\"https://console.aws.amazon.com/cloudwatch/home?region=us-east-1#logStream:group=/aws/sagemaker/ProcessingJobs;prefix=sagemaker-scikit-learn-2021-09-16-09-27-40-683;streamFilter=typeLogStreamPrefix\">CloudWatch Logs</a> after about 5 minutes</b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "display(\n",
    "    HTML(\n",
    "        '<b>Review <a target=\"blank\" href=\"https://console.aws.amazon.com/cloudwatch/home?region={}#logStream:group=/aws/sagemaker/ProcessingJobs;prefix={};streamFilter=typeLogStreamPrefix\">CloudWatch Logs</a> after about 5 minutes</b>'.format(\n",
    "            region, scikit_processing_job_name\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the completion of the Processing Job you can also review the output in the S3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>Review <a target=\"blank\" href=\"https://s3.console.aws.amazon.com/s3/buckets/sagemaker-us-east-1-593402094095/sagemaker-scikit-learn-2021-09-16-09-27-40-683/?region=us-east-1&tab=overview\">S3 output data</a> after the Processing Job has completed</b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "display(\n",
    "    HTML(\n",
    "        '<b>Review <a target=\"blank\" href=\"https://s3.console.aws.amazon.com/s3/buckets/{}/{}/?region={}&tab=overview\">S3 output data</a> after the Processing Job has completed</b>'.format(\n",
    "            bucket, scikit_processing_job_name, region\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Monitor the Processing Job:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AppSpecification': {'ContainerArguments': ['--max-seq-length', '128'],\n",
      "                      'ContainerEntrypoint': ['python3',\n",
      "                                              '/opt/ml/processing/input/code/evaluate_model_metrics.py'],\n",
      "                      'ImageUri': '683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-scikit-learn:0.23-1-cpu-py3'},\n",
      " 'CreationTime': datetime.datetime(2021, 9, 16, 9, 27, 41, 193000, tzinfo=tzlocal()),\n",
      " 'LastModifiedTime': datetime.datetime(2021, 9, 16, 9, 27, 41, 610000, tzinfo=tzlocal()),\n",
      " 'ProcessingInputs': [{'AppManaged': False,\n",
      "                       'InputName': 'model-tar-s3-uri',\n",
      "                       'S3Input': {'LocalPath': '/opt/ml/processing/input/model/',\n",
      "                                   'S3CompressionType': 'None',\n",
      "                                   'S3DataDistributionType': 'FullyReplicated',\n",
      "                                   'S3DataType': 'S3Prefix',\n",
      "                                   'S3InputMode': 'File',\n",
      "                                   'S3Uri': 's3://sagemaker-us-east-1-593402094095/pytorch-training-210916-0857-002-fd13714c/output/model.tar.gz'}},\n",
      "                      {'AppManaged': False,\n",
      "                       'InputName': 'evaluation-data-s3-uri',\n",
      "                       'S3Input': {'LocalPath': '/opt/ml/processing/input/data/',\n",
      "                                   'S3CompressionType': 'None',\n",
      "                                   'S3DataDistributionType': 'FullyReplicated',\n",
      "                                   'S3DataType': 'S3Prefix',\n",
      "                                   'S3InputMode': 'File',\n",
      "                                   'S3Uri': 's3://sagemaker-us-east-1-593402094095/transformed/data/sentiment-test/'}},\n",
      "                      {'AppManaged': False,\n",
      "                       'InputName': 'code',\n",
      "                       'S3Input': {'LocalPath': '/opt/ml/processing/input/code',\n",
      "                                   'S3CompressionType': 'None',\n",
      "                                   'S3DataDistributionType': 'FullyReplicated',\n",
      "                                   'S3DataType': 'S3Prefix',\n",
      "                                   'S3InputMode': 'File',\n",
      "                                   'S3Uri': 's3://sagemaker-us-east-1-593402094095/sagemaker-scikit-learn-2021-09-16-09-27-40-683/input/code/evaluate_model_metrics.py'}}],\n",
      " 'ProcessingJobArn': 'arn:aws:sagemaker:us-east-1:593402094095:processing-job/sagemaker-scikit-learn-2021-09-16-09-27-40-683',\n",
      " 'ProcessingJobName': 'sagemaker-scikit-learn-2021-09-16-09-27-40-683',\n",
      " 'ProcessingJobStatus': 'InProgress',\n",
      " 'ProcessingOutputConfig': {'Outputs': [{'AppManaged': False,\n",
      "                                         'OutputName': 'metrics',\n",
      "                                         'S3Output': {'LocalPath': '/opt/ml/processing/output/metrics',\n",
      "                                                      'S3UploadMode': 'EndOfJob',\n",
      "                                                      'S3Uri': 's3://sagemaker-us-east-1-593402094095/sagemaker-scikit-learn-2021-09-16-09-27-40-683/output/metrics'}}]},\n",
      " 'ProcessingResources': {'ClusterConfig': {'InstanceCount': 1,\n",
      "                                           'InstanceType': 'ml.c5.2xlarge',\n",
      "                                           'VolumeSizeInGB': 30}},\n",
      " 'ResponseMetadata': {'HTTPHeaders': {'content-length': '2289',\n",
      "                                      'content-type': 'application/x-amz-json-1.1',\n",
      "                                      'date': 'Thu, 16 Sep 2021 09:27:41 GMT',\n",
      "                                      'x-amzn-requestid': 'dab2cc22-65a8-4118-b4e6-15e346939754'},\n",
      "                      'HTTPStatusCode': 200,\n",
      "                      'RequestId': 'dab2cc22-65a8-4118-b4e6-15e346939754',\n",
      "                      'RetryAttempts': 0},\n",
      " 'RoleArn': 'arn:aws:iam::593402094095:role/c21581a444556l1011249t1w593-SageMakerExecutionRole-1A68B3IR8R29H',\n",
      " 'StoppingCondition': {'MaxRuntimeInSeconds': 7200}}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "running_processor = sagemaker.processing.ProcessingJob.from_processing_name(\n",
    "    processing_job_name=scikit_processing_job_name, sagemaker_session=sess\n",
    ")\n",
    "\n",
    "processing_job_description = running_processor.describe()\n",
    "\n",
    "pprint(processing_job_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wait for the Processing Job to complete.\n",
    "\n",
    "### _This cell will take approximately 5-10 minutes to run._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....................................................................................................!CPU times: user 379 ms, sys: 62.3 ms, total: 441 ms\n",
      "Wall time: 8min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "running_processor.wait(logs=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Please wait until ^^ Processing Job ^^ completes above_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='c3w1-3.3.'></a>\n",
    "### 3.3. Inspect the processed output data\n",
    "\n",
    "Let's take a look at the results of the Processing Job. Get the S3 bucket location of the output metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-593402094095/sagemaker-scikit-learn-2021-09-16-09-27-40-683/output/metrics\n"
     ]
    }
   ],
   "source": [
    "processing_job_description = running_processor.describe()\n",
    "\n",
    "output_config = processing_job_description[\"ProcessingOutputConfig\"]\n",
    "for output in output_config[\"Outputs\"]:\n",
    "    if output[\"OutputName\"] == \"metrics\":\n",
    "        processed_metrics_s3_uri = output[\"S3Output\"][\"S3Uri\"]\n",
    "\n",
    "print(processed_metrics_s3_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List the content of the folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-16 09:35:57      21158 confusion_matrix.png\n",
      "2021-09-16 09:35:57         56 evaluation.json\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls $processed_metrics_s3_uri/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test accuracy can be pulled from the `evaluation.json` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: {'metrics': {'accuracy': {'value': 0.7249190938511327}}}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "metrics_json = sagemaker.s3.S3Downloader.read_file(\"{}/evaluation.json\".format(\n",
    "    processed_metrics_s3_uri\n",
    "))\n",
    "\n",
    "print('Test accuracy: {}'.format(json.loads(metrics_json)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy image with the confusion matrix generated during the model evaluation into the folder `generated`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-us-east-1-593402094095/sagemaker-scikit-learn-2021-09-16-09-27-40-683/output/metrics/confusion_matrix.png to generated/confusion_matrix.png\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp $processed_metrics_s3_uri/confusion_matrix.png ./generated/\n",
    "\n",
    "import time\n",
    "time.sleep(10) # Slight delay for our notebook to recognize the newly-downloaded file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show and review the confusion matrix, which is a table of all combinations of true (actual) and predicted labels. Each cell contains the number of the reviews for the corresponding sentiments. You can see that the highest numbers of the reviews appear in the diagonal cells, where the predicted sentiment equals the actual one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<img src='./generated/confusion_matrix.png'>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "\n",
    "<img src='./generated/confusion_matrix.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload the notebook into S3 bucket for grading purposes.\n",
    "\n",
    "**Note:** you may need to click on \"Save\" button before the upload."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: ./C3_W1_Assignment.ipynb to s3://sagemaker-us-east-1-593402094095/C3_W1_Assignment_Learner.ipynb\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp ./C3_W1_Assignment.ipynb s3://$bucket/C3_W1_Assignment_Learner.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
